\documentclass[12pt, letterpaper, onecolumn]{exam}

% ==========================
% ПАКЕТЫ
% ==========================

\usepackage{amsmath,amssymb,amsthm}
\usepackage{array}
\usepackage[english, russian]{babel}
\usepackage{enumitem}
\usepackage[T2A]{fontenc}
\usepackage{fontspec}
\usepackage[lmargin=71pt, tmargin=1.2in, rmargin=71pt, bmargin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{polyglossia}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{tcolorbox}
\usepackage{xcolor}
\usepackage[matrix,arrow]{xy}

% ==========================
% НАСТРОЙКИ ЯЗЫКА / ШРИФТА
% ==========================

\setmainfont{Times New Roman}
\setdefaultlanguage{russian}
\setotherlanguage{english}

\pagecolor{white}
\color{black}

% ==========================
% TikZ БИБЛИОТЕКИ
% ==========================

\usetikzlibrary{
  angles,
  arrows,
  arrows.meta,
  automata,
  backgrounds,
  calc,
  decorations.markings,
  fillbetween,
  intersections,
  patterns,
  petri,
  positioning,
  quotes,
  snakes,
  through
}

% ==========================
% ОФОРМЛЕНИЕ EXAM
% ==========================

\pointsdroppedatright{}
\printanswers{}
\renewcommand{\solutiontitle}{\noindent \textbf{}\,}

% Обводка кружком
\newcommand{\circled}[1]{%
  \tikz[baseline=(char.base)]{
    \node[shape=circle,draw=red,text=red,inner sep=2pt,line width=0.6pt] (char) {#1};
  }%
}

% ==========================
% ОПРЕДЕЛЕНИЯ И ТЕОРЕМЫ
% ==========================

\theoremstyle{definition}
\newtheorem{definition}{Определение}[section]

\theoremstyle{plain}
\newtheorem{theorem}{Теорема}[section]

% ==========================
% Цвета и tcolorbox
% ==========================

\tcbuselibrary{skins, breakable}
\definecolor{sand}{RGB}{226,202,108}

\tcbset{
  colback=white,
  colframe=black,
  fonttitle=\bfseries,
  arc=3pt,
  boxrule=0.8pt,
  breakable,
  enhanced
}

% Ответ в рамочке
\newtcolorbox{answerbox}[1][]{
  title={Ответ},
  colback=white,
  colframe=sand!80!black,
  coltitle=sand!40!black,
  #1
}

% ==========================
% Нумерованные вопросы
% ==========================

\newcounter{colquestion}
\newcommand{\colquestion}[1]{%
  \refstepcounter{colquestion}%
  \noindent\textbf{\thecolquestion.\ #1}%
}

% Нумератор теорем (для списка вопросов)
\newcounter{thcounter}
\newcommand{\theoremq}[1]{%
  \refstepcounter{thcounter}%
  \noindent\textbf{\thethcounter.\ Th.} #1%
}

% ==========================
% ДОКУМЕНТ
% ==========================

\begin{document}

\title{Подготовка к коллоквиуму по линейной алгебре}
\author{}
\date{}
\maketitle

% ==========================
% ЧАСТЬ I. ОПРЕДЕЛЕНИЯ
% ==========================

\section*{Часть I. Определения}
\addcontentsline{toc}{section}{Часть I. Определения}

% 1. Линейная система

\colquestion{Что такое линейная система?}

\begin{answerbox}
	adadaojsd
	Линейным уравнением с неизвестными $x_1,\dots,x_n$ называется уравнение вида
	\[
		\alpha_1 x_1 + \dots + \alpha_n x_n = \beta,
	\]
	где $\alpha_1,\dots,\alpha_n,\beta$~--- фиксированные числа (обычно вещественные).

	Линейная система (система линейных уравнений)~--- это набор одного или нескольких таких уравнений, в каждом из которых неизвестные входят только в первой степени.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, \S1.1.1 ``Основные понятия'', стр.\ 5--6.}
\end{answerbox}

\bigskip

% 2. Решение линейной системы

\colquestion{Что такое решение линейной системы?}

\begin{answerbox}

	\textbf{Определение 1.1.3.} Пусть дана линейная система

	\[
		\begin{cases}
			a_{11}x_1 + \cdots + a_{1n}x_n = b_1 \\
			\vdots                               \\
			a_{m1}x_1 + \cdots + a_{mn}x_n = b_m
		\end{cases}
	\]

	Решением системы называется набор чисел \((s_1, s_2, \dots, s_n)\), такой что, при подстановке

	\[
		x_1 \mapsto s_1, \, x_2 \mapsto s_2, \dots, x_n \mapsto s_n
	\]

	в систему, мы получаем тождественные равенства.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, \S1.1.1 ``Основные понятия'', стр.\ 6--7.}
\end{answerbox}

\bigskip

% 3. Геометрический смысл решений

\colquestion{Как понимать геометрически решение линейной системы?}

\begin{answerbox}
	Каждое одно линейное уравнение в $n$ переменных задаёт гиперплоскость в пространстве $\mathbb{R}^n$ (прямую при $n=2$, плоскость при $n=3$ и т.\,д.). Множество всех решений линейной системы есть пересечение гиперплоскостей, соответствующих её уравнениям. В зависимости от взаимного положения этих гиперплоскостей пересечение (и потому множество решений) может быть пустым, состоять из одной точки или представлять собой аффинное подпространство (прямую, плоскость, более высокомерное аффинное подпространство).

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, примеры 1.4--1.6 и замечание о трёх возможных случаях, стр.\ 7--8.}
\end{answerbox}

\bigskip

% 4. Сколько решений может иметь линейная система?

\colquestion{Сколько решений может иметь линейная система?}

\begin{answerbox}
	Линейная система система может:
	\begin{itemize}
		\item не иметь решений (несовместная система);
		\item иметь единственное решение;
		\item иметь бесконечно много решений (множество решений~--- ненулевое аффинное подпространство).
	\end{itemize}
	Эти три случая наглядно демонстрируются примерами для двух уравнений с двумя неизвестными: пересекающиеся, параллельные и совпадающие прямые.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, примеры 1.4--1.6 и последующее замечание, стр.\ 7--9.}
\end{answerbox}

\bigskip

% 5. Матричное обозначение линейной системы

\colquestion{Что такое матричное обозначение линейной системы?}

\begin{answerbox}
	Пусть система имеет вид
	\[
		\begin{cases}
			a_{11}x_1 + \dots + a_{1n}x_n = b_1, \\
			\vdots                               \\
			a_{m1}x_1 + \dots + a_{mn}x_n = b_m.
		\end{cases}
	\]
	Матрицей коэффициентов называется матрица
	\[
		A =
		\begin{pmatrix}
			a_{11} & \dots  & a_{1n} \\
			\vdots & \ddots & \vdots \\
			a_{m1} & \dots  & a_{mn}
		\end{pmatrix},
		\qquad
		x =
		\begin{pmatrix}
			x_1 \\ \vdots\\ x_n
		\end{pmatrix},
		\qquad
		b =
		\begin{pmatrix}
			b_1 \\ \vdots\\ b_m
		\end{pmatrix}.
	\]
	Тогда система компактно записывается в виде матричного уравнения
	\[
		A x = b,
	\]
	что и называется матричным обозначением линейной системы.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, \S1.1.2 ``Матричное обозначение'', стр.\ 8--9.}
\end{answerbox}

\bigskip

% 6. Элементарные преобразования

\colquestion{Что такое элементарные преобразования?}

\begin{answerbox}
	Элементарными преобразованиями строк матрицы (в частности, расширенной матрицы линейной системы) называют операции трёх типов:
	\begin{itemize}
		\item прибавить к одной строке другую строку, умноженную на число;
		\item поменять местами две строки матрицы;
		\item умножить строку матрицы на ненулевое число.
	\end{itemize}
	Аналогично определяются элементарные преобразования столбцов. Две матрицы называются \emph{эквивалентными по строкам}, если одну можно получить из другой конечной последовательностью таких элементарных преобразований строк.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, определение 1.1.4, стр.\ 11--12.}
\end{answerbox}

\bigskip

% 7. Расширенная матрица

\colquestion{Что такое расширенная матрица линейной системы?}

\begin{answerbox}
	Пусть система $m$ уравнений с $n$ неизвестными записана как
	\[
		\begin{cases}
			a_{11}x_1 + \dots + a_{1n}x_n = b_1, \\
			\vdots                               \\
			a_{m1}x_1 + \dots + a_{mn}x_n = b_m.
		\end{cases}
	\]
	\emph{Матрицей коэффициентов} называется матрица $A = (a_{ij})_{m\times n}$, а \emph{расширенной матрицей}~--- матрица, в которую добавлен столбец свободных членов:
	\[
		\left(
		\begin{array}{ccc|c}
				a_{11} & \dots  & a_{1n} & b_1    \\
				\vdots & \ddots & \vdots & \vdots \\
				a_{m1} & \dots  & a_{mn} & b_m
			\end{array}
		\right).
	\]
	Расширенная матрица одновременно кодирует и коэффициенты при неизвестных, и правые части уравнений.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, пример 1.7, стр.\ 9--10.}
\end{answerbox}

\bigskip

% 8. Матрица коэффициентов

\colquestion{Что такое матрица коэффициентов линейной системы?}

\begin{answerbox}
	Для линейной системы, записанной как
	\[
		\begin{cases}
			a_{11}x_1 + \dots + a_{1n}x_n = b_1, \\
			\vdots                               \\
			a_{m1}x_1 + \dots + a_{mn}x_n = b_m,
		\end{cases}
	\]
	матрицей коэффициентов называется прямоугольная числовая матрица $A = (a_{ij})_{m\times n}$, содержащая только коэффициенты при неизвестных, без столбца свободных членов:
	\[
		A =
		\begin{pmatrix}
			a_{11} & \dots  & a_{1n} \\
			\vdots & \ddots & \vdots \\
			a_{m1} & \dots  & a_{mn}
		\end{pmatrix}.
	\]
	Она описывает линейный оператор, сопоставляющий вектору неизвестных $x$ вектор левых частей $Ax$.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, пример 1.7, стр.\ 9.}
\end{answerbox}

\bigskip

% 9. Эквивалентные матрицы

\colquestion{Что значит фраза ``матрицы эквивалентны''?}

\begin{answerbox}
	Говорят, что две матрицы $M$ и $M'$ \emph{эквивалентны по строкам}, если одну из них можно получить из другой конечной последовательностью элементарных преобразований строк. Аналогично определяют эквивалентность по столбцам. В контексте линейных систем эквивалентные по строкам расширенные матрицы соответствуют системам с одним и тем же множеством решений.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, определение 1.1.4 и теорема 1.1.1, стр.\ 11--13.}
\end{answerbox}

\bigskip

% 10. Ведущие элементы

\colquestion{Что такое ведущие элементы строки матрицы?}

\begin{answerbox}
	Строка матрицы называется \emph{ненулевой}, если в ней есть хотя бы один ненулевой элемент. В такой строке \emph{ведущим элементом} называется первый слева ненулевой элемент этой строки. При приведении матриц к ступенчатому виду именно положения ведущих элементов определяют структуру ступенчатой матрицы.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, \S1.1.4 ``Ступенчатый вид матрицы'', стр.\ 12--13.}
\end{answerbox}

\bigskip

% 11. Ступенчатый вид

\colquestion{Что такое ступенчатый вид матрицы?}

\begin{answerbox}
	Матрица называется имеющей \emph{ступенчатый вид}, если выполняются следующие условия:
	\begin{itemize}
		\item все нулевые строки (если есть) расположены ниже всех ненулевых;
		\item в каждой ненулевой строке выбран ведущий (первый слева ненулевой) элемент;
		\item номера столбцов, в которых стоят ведущие элементы, строго возрастают при переходе сверху вниз (то есть ведущий элемент каждой следующей ненулевой строки расположен правее ведущего элемента предыдущей).
	\end{itemize}
	Такая структура образует характерную ``лестницу'' из ведущих элементов.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, определение 1.1.5 и пример 1.9, стр.\ 13--14.}
\end{answerbox}

\bigskip

% 12. Приведённый ступенчатый вид

\colquestion{Что такое приведённый (улучшенный) ступенчатый вид матрицы?}

\begin{answerbox}
	Матрица называется находящейся в \emph{приведённом ступенчатом виде}, если:
	\begin{itemize}
		\item она имеет ступенчатый вид;
		\item каждый ведущий элемент ненулевой строки равен $1$;
		\item в столбце каждого ведущего элемента все остальные элементы равны $0$ (то есть ведущий элемент~--- единственный ненулевой в своём столбце).
	\end{itemize}
	Такой вид ещё называют \emph{редуцированным ступенчатым} и он соответствует максимально упрощённой форме при методе Гаусса--Жордана.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, определение 1.1.6 и пример 1.10, стр.\ 13--14.}
\end{answerbox}

\bigskip

% 13. Метод Гаусса

\colquestion{Что такое метод Гаусса для решения линейных систем?}

\begin{answerbox}
	Метод Гаусса~--- это алгоритм решения линейных систем, основанный на последовательном применении элементарных преобразований строк к расширенной матрице системы с целью привести её к верхнетреугольному или ступенчатому виду, а затем выполнить обратный ход (выражение главных неизвестных через свободные). Схематически:
	\begin{itemize}
		\item составить расширенную матрицу системы;
		\item с помощью элементарных преобразований привести её к ступенчатому виду;
		\item проанализировать совместность системы (наличие строк вида $0=\beta\neq 0$);
		\item при совместности выразить главные переменные через свободные, двигаясь снизу вверх.
	\end{itemize}
	Метод сохраняет множество решений, так как элементарные преобразования строк эквивалентны преобразованию системы к равносильной.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, \S1.1.3 и \S1.1.5 ``Метод Гаусса'', стр.\ 9--11 и 15--16.}
\end{answerbox}

\bigskip

% 14. Векторное пространство

\colquestion{Что такое векторное пространство над $\mathbb{R}$?}

\begin{answerbox}
	Непустое множество $V$ называется \emph{векторным пространством над $\mathbb{R}$}, если в нём заданы операции сложения $V\times V\to V$, $(a,b)\mapsto a+b$, и умножения на скаляр $\mathbb{R}\times V\to V$, $(\lambda,a)\mapsto\lambda a$, такие что выполняются восемь аксиом (свойств):
	\begin{enumerate}
		\item \textbf{$a + (b + c) = (a + b) + c$}, для любых $a, b, c \in V$.

		\item \textbf{$a + b = b + a$}, для любых $a, b \in V$.

		\item Существует такой вектор, называемый \textit{нулевым вектором}, 
		\textbf{$o \in V$}, что \textbf{$o + a = a$}, для любого $a \in V$.

		\item Для любого вектора $a \in V$ существует такой вектор 
		\textbf{$-a \in V$}, что \textbf{$a + (-a) = o$}.

		\item \textbf{$(\alpha + \beta)\cdot a = \alpha\cdot a + \beta\cdot a$} для любых чисел 
		$\alpha, \beta \in \mathbb{R}$ и любого вектора $a \in V$.

		\item \textbf{$(\alpha\beta)\cdot a = \alpha\cdot(\beta\cdot a)$} для любых чисел 
		$\alpha, \beta \in \mathbb{R}$ и любого вектора $a \in V$.

		\item \textbf{$\alpha\cdot(a + b) = \alpha\cdot a + \alpha\cdot b$} для любых векторов 
		$a, b \in V$ и любого числа $\alpha \in \mathbb{R}$.

		\item \textbf{$1\cdot a = a$} для любого вектора $a \in V$.
	\end{enumerate}
	Эти аксиомы абстрактно формализуют свойства привычных векторов и столбцов чисел.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#2, определение 2.1.1, стр.\ 16--18.}
\end{answerbox}

\bigskip

% 15. Векторное подпространство

\colquestion{Что такое векторное подпространство векторного пространства $V$?}

\begin{answerbox}
	Пусть $W \subseteq V$ - некоторое непустое подмножество в векторном пространстве $V$, тогда если
	\begin{itemize}
		\item $0_V\in W$;
		\item Для любых $w,w'\in W$, верно что $w+w' \in W$;
		\item Для любого $w\in W$ и любого числа $\alpha\in\mathbb{R}$, верно что $\alpha \cdot w \in W$.
	\end{itemize}
	то такое подмножество называется \emph{векторным подпространством} пространства $V$. \\
	При этом $W$ является векторным пространством относительно тех же операций, которые определены в изначальном пространстве ($V$).

	\textit{Источник: \emph{Linear-Algebra}, лекция \#2, определение 2.1.2 и предложение 2.1.1, стр.\ 23--24.}
\end{answerbox}

\bigskip

% 16. Линейная комбинация

\colquestion{Что такое линейная комбинация векторов?}

\begin{answerbox}
	Пусть $v_1,\dots,v_k\in V$ и $\alpha_1,\dots,\alpha_k\in\mathbb{R}$. Вектор
	\[
		\alpha_1 v_1 + \dots + \alpha_k v_k
	\]
	называется \emph{линейной комбинацией} векторов $v_1,\dots,v_k$ с коэффициентами $\alpha_1,\dots,\alpha_k$. Говорят также, что этот вектор линейно выражается через $v_1,\dots,v_k$.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#3, определение 2.2.1, стр.\ 24--25.}
\end{answerbox}

\bigskip

% 17. Линейная оболочка

\colquestion{Что такое линейная оболочка?}

\begin{answerbox}
	Пусть $S = \{v_1,\dots,v_k\}\subset V$. \\
	\emph{Линейной оболочкой} множества $S$ называется множество всех линейных комбинаций векторов из $S$:
	\[
		\operatorname{Span_{\mathbb{R}}}(S) = \left\{ \alpha_1 v_1 + \dots + \alpha_k v_k \,\middle|\, \alpha_1,\dots,\alpha_k\in\mathbb{R} \right\}.
	\]
	\textit{Источник: \emph{Linear-Algebra}, лекция \#3, \S2.2.2 ``Понятие линейной оболочки'', стр.\ 26--27.}
\end{answerbox}

\bigskip

% 18. Линейная независимость

\colquestion{Что такое линейно независимое подмножество в векторном пространстве?}

\begin{answerbox}
	Подмножество $S \subset V$ называется \emph{линейно независимым}, если из для каждого конечного набора векторов из $S$,
	$s_1,\ldots,s_k$ из равенства
	\[
		\alpha_1 s_1 + \cdots + \alpha_ks_k = 0
	\]
	вытекает, что $\alpha_1 = \dots = \alpha_k = 0$.\\ 
	Если же существует нетривиальная (не все коэффициенты нулевые) линейная комбинация некоторых вектор $\in S$, равная нулю, то говорят, что $S$ - \emph{линейно зависимое подмножество}.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#3, определение 2.2.3, стр.\ 26--27.}
\end{answerbox}

\bigskip

% 19. Базис

\colquestion{Что такое базис векторного пространства?}

\begin{answerbox}
	Если $W=\operatorname{Span}_{\mathbb{R}}(S)$, то говорят, что векторное пространство $W$ \emph{порождено множеством $S$}.
	Если же множество $S$ - линейно независимо, то в таком случае говорят, что $S$ - \emph{базис} векторного пространства $W$.

	Если $S$ конечно и имеет мощность $n$, то говорят, что пространство $W$ конечномерное и имеет размерность $n$. \\
	Если $S$ бесконечно, то говорят, что пространство $W$ , бесконечномерно.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#4, \S2.3.1 ``Понятие базиса и координаты вектора'', стр.\ 30.}
\end{answerbox}

\bigskip

% 20. Координаты вектора

\colquestion{Что такое координаты вектора?}

\begin{answerbox}
	Пусть $E = (e_1,\dots,e_n)$~--- базис пространства $V$. Тогда для любого вектора $v\in V$ существует единственное представление
	\[
		v = \alpha_1 e_1 + \dots + \alpha_ne_n,
	\]
	где $\alpha_1,\dots,\alpha_n\in\mathbb{R}$. Числа $\alpha_1,\dots,\alpha_n$ называются \emph{координатами} вектора $v$ в базисе $E$ и принято это записывать в виде
	\[
		v_E = (\alpha_1,\dots,\alpha_n)^T
	\]
	У нулевого вектора $o$ координаты состоят из нулей.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#4, \S2.3.1, стр.\ 30.}
\end{answerbox}

\bigskip

% 21. R^n

\colquestion{Что такое $\mathbb{R}^n$?}

\begin{answerbox}
	Под $\mathbb{R}^n$ понимают множество всех упорядоченных наборов (столбцов или строк) длины $n$ из вещественных чисел:
	\[
		\mathbb{R}^n = \{ (x_1,\dots,x_n)\mid x_i\in\mathbb{R} \}.
	\]
	С покомпонентными операциями сложения и умножения на скаляр $\mathbb{R}^n$ является базовым примером векторного пространства над $\mathbb{R}$.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#2, пример 2.2 и последующие обсуждения, стр.\ 18--22.}
\end{answerbox}

\bigskip

% 22. Инъекция, сюръекция, биекция

\colquestion{Что такое инъекция, сюръекция и биекция?}

\begin{answerbox}
	Пусть $f\colon X\to Y$~--- отображение множеств.
	\begin{itemize}
		\item $f$ называется \emph{инъекцией}, если из $f(x_1)=f(x_2)$ следует $x_1=x_2$; эквивалентно, различные элементы $X$ переходят в различные элементы $Y$.
		\item $f$ называется \emph{сюръекцией}, если для любого $y\in Y$ существует $x\in X$ такое, что $f(x)=y$, то есть образ $f$ совпадает со всем $Y$.
		\item $f$ называется \emph{биекцией}, если оно одновременно инъективно и сюръективно; в этом случае существует и единственно обратное отображение $f^{-1}\colon Y\to X$.
	\end{itemize}

	\textit{Источник: \emph{Linear-Algebra}, лекция \#5, \S2.4.1 ``Инъекция, сюръекция и биекция'', стр.\ 34.}
\end{answerbox}

\bigskip

% 23. Изоморфизм векторных пространств

\colquestion{Что такое изоморфизм векторных пространств?}

\begin{answerbox}
	Пусть $V, W$ — два векторных пространства. Биективное отображение
	\[
	\varphi : V \to W
	\]
	называется \emph{изоморфизмом}, если для любых векторов $a, b \in V$ и любого числа 
	$\lambda \in \mathbb{R}$
	\[
	\varphi(a + b) = \varphi(a) + \varphi(b), \qquad
	\varphi(\lambda a) = \lambda \varphi(a).
	\]

	Векторные пространства $V, W$ называются \emph{изоморфными}, если существует хотя бы один 
	изоморфизм $V \to W$. В таком случае пишут $V \cong W$.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#5, \S2.4.2 ``Понятие изоморфизма'', стр.\ 39.}
\end{answerbox}

\bigskip

% 24. Линейное отображение

\colquestion{Что такое линейное отображение векторных пространств?}

\begin{answerbox}
	Пусть $V$ и $W$~--- векторные пространства над $\mathbb{R}$. Отображение $\varphi\colon V\to W$ называется \emph{линейным}, если для любых $a,b\in V$ и любого числа $\lambda\in\mathbb{R}$ выполняются свойства:
	\[
		\varphi(a+b) = \varphi(a)+\varphi(b),\qquad
		\varphi(\lambda a) = \lambda\,\varphi(a).
	\]
	Из этих двух свойств выводятся и другие: сохранение нулевого вектора, перевод линейных комбинаций в линейные комбинации с теми же коэффициентами и т.\,д.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#6, определение 3.1.1, стр.\ 42.}
\end{answerbox}

\bigskip

% 25. Матрица линейного отображения

\colquestion{Что такое матрица линейного отображения? О чём говорят её столбцы?}

\begin{answerbox}
	Пусть $V=\mathbb{R}^n$ и $W=\mathbb{R}^m$ со стандартными базисами $e_1,\dots,e_n$ и $f_1,\dots,f_m$. Линейное отображение $\varphi\colon \mathbb{R}^n\to\mathbb{R}^m$ однозначно задаётся образами базисных векторов:
	\[
		\varphi(e_j) =
		\begin{pmatrix}
			a_{1j} \\ \vdots\\ a_{mj}
		\end{pmatrix},\quad j=1,\dots,n.
	\]
	Матрицей линейного отображения $\varphi$ в этих базисах называется матрица
	\[
		A =
		\begin{pmatrix}
			a_{11} & \dots  & a_{1n} \\
			\vdots & \ddots & \vdots \\
			a_{m1} & \dots  & a_{mn}
		\end{pmatrix}.
	\]
	$j$-й столбец этой матрицы есть координатный столбец вектора $\varphi(e_j)$, то есть показывает, как отображение действует на $j$-й базисный вектор.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#6, \S3.1.2 и замечание 3.1.1, стр.\ 41--43.}
\end{answerbox}

\bigskip

% 26. Композиция на матричном языке

\colquestion{Как описывается композиция линейных отображений на матричном языке?}

\begin{answerbox}
	Пусть заданы линейные отображения
	\[
		g\colon \mathbb{R}^n\to\mathbb{R}^k,\qquad f\colon \mathbb{R}^k\to\mathbb{R}^m,
	\]
	записанные в стандартных базисах матрицами $A$ (размера $k\times n$) и $B$ (размера $m\times k$) соответственно. Тогда композиция $f\circ g\colon \mathbb{R}^n\to\mathbb{R}^m$ является линейным отображением, и его матрица в стандартных базисах равна произведению матриц:
	\[
		[f\circ g] = B A.
	\]
	Действительно, для любого $x\in\mathbb{R}^n$ имеем $g(x)=A x$, $f(g(x)) = B (A x) = (B A) x$.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#7, \S3.2.2 ``Композиция отображений и её матричное представление'', стр.\ 51--52.}
\end{answerbox}

\bigskip

% 27. Обратная матрица

\colquestion{Что такое обратная матрица?}

\begin{answerbox}
	\textbf{Определение 3.3.1.}
	В случае когда рассматривается линейное отображение 
	$\varphi : V \to V$, то оно называется \emph{линейным оператором}.
	Если $\psi : V \to V$ — такой линейный оператор, что 
	$\varphi \circ \psi = \psi \circ \varphi = \mathrm{id}_V$, 
	то $\psi$ называется \emph{обратным к} $\varphi$ и обозначается так 
	$\psi = \varphi^{-1}$.

	\begin{tcolorbox}[colback=blue!5!white,colframe=blue!50!black,title=Важное замечание]
	Мы ограничиваемся случаем, когда пространство $V$ конечномерное, 
	$\dim(V)=n<\infty$. В таком случае, согласно Теореме~2.4.2, имеем 
	$V \cong \mathbb{R}^n$. Далее, согласно Теореме~3.1.1, наш оператор 
	задаётся квадратной матрицей $A \in \mathrm{Mat}_{n\times n}(\mathbb{R})$.
	\end{tcolorbox}

	\textbf{Определение 3.3.2.}
	Пусть дан линейный оператор $\varphi : \mathbb{R}^n \to \mathbb{R}^n$ 
	и $A$ — его матрица. Пусть у него имеется обратный $\varphi^{-1}$, 
	тогда матрица обратного оператора называется \emph{обратной матрицей} к $A$ 
	и обозначается как $A^{-1}$.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#8, \S3.3.2 ``Нахождение обратной матрицы'', стр.\ 54.}
\end{answerbox}

\bigskip

% 28. Линейные операторы в малых размерностях

\colquestion{Опишите линейные операторы в малых размерностях.}

\begin{answerbox}
	Линейный оператор на $\mathbb{R}^1$ задаётся умножением на число: любая линейная функция $f\colon\mathbb{R}\to\mathbb{R}$ имеет вид $f(x)=\lambda x$ и описывается матрицей $(\lambda)$. На $\mathbb{R}^2$ и $\mathbb{R}^3$ линейные операторы описываются соответственно $2\times 2$ и $3\times 3$ матрицами; геометрически это всевозможные комбинации растяжений, сжатий, поворотов, отражений и сдвигов вдоль подпространств, сохраняющие начало координат. Конкретные типичные примеры: диагональные операторы (независимое масштабирование по осям), повороты плоскости, операторы проекции на прямую/плоскость, отражения относительно подпространств.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#8, \S3.3.1 ``Линейные операторы в малых размерностях'', стр.\ 54--57.}
\end{answerbox}

\bigskip

% 29. Элементарная матрица

\colquestion{Что такое элементарная матрица? Как это связано с элементарными преобразованиями?}

\begin{answerbox}
	\emph{Элементарные матрицы} — это квадратные матрицы размера $n \times n$ 
	($n \ge 1$) вида $L_{i,j}(\lambda)$, $T_{i,j}$, $D_i(\lambda)$, где 
	$\lambda \in \mathbb{R}$. Они описываются следующим образом:

	\begin{enumerate}
		\item $L_{i,j}(\lambda)$ получается из единичной матрицы $E$ путём прибавления 
		к $j$-ой строке $i$-ой, умноженной на $\lambda$.

		\item $T_{i,j}$ получается из единичной матрицы путём перемены местами 
		$i$-ой и $j$-ой строк.

		\item $D_i(\lambda)$ получается из единичной матрицы путём умножения 
		её $i$-ой строки на число $\lambda \ne 0$.
	\end{enumerate}

	\textit{Источник: \emph{Linear-Algebra}, лекция \#8, \S3.3.3 ``Элементарные матрицы'', стр.\ 59.}
\end{answerbox}

\bigskip

% 30. Перестановка, её знак и циклическая запись

\colquestion{Что такое перестановка? Что такое её знак? Как умножаются перестановки и что такое обратная перестановка? Что такое циклическая запись перестановки?}

\begin{answerbox}
	\emph{Перестановкой} $n$ элементов называется биекция $\sigma\colon\{1,\dots,n\}\to\{1,\dots,n\}$. \\
	
	Под \emph{знаком} перестановки $\sigma \in \mathfrak{S}_n$ мы понимаем чётность числа её всех 
	\emph{инверсий}. Инверсией называется такая пара $(i,j)$, где $1 \le i < j \le n$, но 
	$\sigma(i) > \sigma(j)$. \\
	\emph{Знак перестановки $\sigma$}, обозначаемый $\operatorname{sign}(\sigma) = (-1)^{|R(\sigma)|}$, где $|R(\sigma)|$ - число инверсий в перестановке $\sigma$. \\

	Композицией (умножением) перестановок $\sigma$ и $\tau$ называется перестановка $\sigma\circ\tau$, действующая по правилу $(\sigma\circ\tau)(i) = \sigma(\tau(i))$. \\ 
	Обратная перестановка $\sigma^{-1}$~--- это биекция, удовлетворяющая $\sigma\circ\sigma^{-1} = \sigma^{-1}\circ\sigma = \operatorname{id}$.

	\emph{Циклической записью} перестановки называют её представление в виде произведения независимых циклов, например
	\[
		\sigma = (1\ 3\ 2)(4\ 5),
	\]
	где каждый цикл показывает, как перестановка циклически переупорядочивает соответствующие элементы.

	\textit{Источник: \emph{Linear-Algebra}, глава 4, \S4.1.1--4.1.4 ``Основные понятия, умножение перестановок, знак, циклическая запись'', стр.\ 63--73.}
\end{answerbox}

\bigskip

% 31. Бивектор и появление детерминанта

\colquestion{Что такое бивектор? И как появляется детерминант матрицы $2\times 2$? И что происходит дальше? Объясните как появляется детерминант матрицы произвольного размера.}

\begin{answerbox}
	\textbf{Определение 4.2.1.}
	Мы будем считать две пары $(\vec{a}, \vec{b})$, $(\vec{a}\,', \vec{b}\,')$ векторов 
	\emph{эквивалентными}, если для построенных на них параллелограммах выполняются условия:

	\begin{enumerate}
		\item Они имеют одинаковую площадь.
		\item Направления вращения у них совпадают.
	\end{enumerate}

	Класс эквивалентности таких пар мы называем \emph{бивектором} и обозначаем так 
	$\vec{a} \wedge \vec{b}$.

	\bigskip

	\textbf{Как появляется детерминант матрицы 2x2?}

	\bigskip

		Теперь мы хотим понять, как произвольный бивектор $\vec{a} \wedge \vec{b}$ связан 
	с бивектором $\vec{e}_1 \wedge \vec{e}_2$, который построен на базисных векторах 
	$\vec{e}_1 = (1,0)^{\mathsf{T}},\; \vec{e}_2 = (0,1)^{\mathsf{T}}$.

	\begin{tcolorbox}[colback=green!5!white, colframe=green!40!black, title=Наблюдение 4.7]
	Пусть векторы $\vec{a}$ и $\vec{b}$ выражены через векторы $\vec{e}_1$ и $\vec{e}_2$ следующим образом:
	\[
	\vec{a} = a_1 \vec{e}_1 + a_2 \vec{e}_2,\qquad
	\vec{b} = b_1 \vec{e}_1 + b_2 \vec{e}_2.
	\]

	Тогда, используя свойства операции $\wedge$, имеем:
	\[
	\vec{a} \wedge \vec{b} 
	= (a_1 \vec{e}_1 + a_2 \vec{e}_2)\wedge (b_1 \vec{e}_1 + b_2 \vec{e}_2)
	\]
	\[
	= a_1 b_1 (\vec{e}_1 \wedge \vec{e}_1)
	+ a_1 b_2 (\vec{e}_1 \wedge \vec{e}_2)
	+ a_2 b_1 (\vec{e}_2 \wedge \vec{e}_1)
	+ a_2 b_2 (\vec{e}_2 \wedge \vec{e}_2).
	\]

	Так как $\vec{e}_1 \wedge \vec{e}_1 = \vec{e}_2 \wedge \vec{e}_2 = 0$ и 
	$\vec{e}_2 \wedge \vec{e}_1 = -\,\vec{e}_1 \wedge \vec{e}_2$, то мы получаем:
	\[
	\vec{a} \wedge \vec{b} 
	= (a_1 b_2 - a_2 b_1)(\vec{e}_1 \wedge \vec{e}_2).
	\]
	\end{tcolorbox}

	\begin{tcolorbox}[colback=blue!5!white, colframe=blue!50!black, title=Важное замечание]
	Выражение в скобках — это в точности детерминант матрицы коэффициентов:
	\[
	A = 
	\begin{pmatrix}
	a_1 & a_2 \\
	b_1 & b_2
	\end{pmatrix}.
	\]

	{\large \(\Rightarrow\)} Таким образом мы можем записать
	\[
	\vec{a} \wedge \vec{b} = \det(A)\cdot (\vec{e}_1 \wedge \vec{e}_2).
	\]
	\end{tcolorbox}

	\bigskip

	\textbf{Что происходит дальше?}

	\bigskip

		\begin{tcolorbox}[colback=green!5!white, colframe=green!40!black, title=Наблюдение 4.11]
	Рассмотрим $n$-мерное векторное пространство с базисом 
	$\{\vec{e}_1, \vec{e}_2, \dots, \vec{e}_n\}$. Аналогично предыдущим случаям:

	\begin{itemize}
		\item На прямой: $1$-вектор — направленный отрезок (1-мерный объём).
		\item На плоскости: $2$-вектор — направленный параллелограмм (2-мерный объём).
		\item В пространстве: $3$-вектор — направленный параллелепипед (3-мерный объём).
		\item В $n$-мерном пространстве: $n$-вектор — направленный $n$-мерный параллелепипед ($n$-мерный объём).
	\end{itemize}
	\end{tcolorbox}

	\bigskip

	\textbf{Общая формула детерминанта n-мерной матрицы}

	\bigskip

\textbf{Определение 4.2.3.}
Рассмотрим $n$ векторов в $n$-мерном пространстве:
\[
\vec{a}_1 = a_{11}\vec{e}_1 + a_{12}\vec{e}_2 + \cdots + a_{1n}\vec{e}_n,
\]
\[
\vec{a}_2 = a_{21}\vec{e}_1 + a_{22}\vec{e}_2 + \cdots + a_{2n}\vec{e}_n,
\]
\[
\vdots
\]
\[
\vec{a}_n = a_{n1}\vec{e}_1 + a_{n2}\vec{e}_2 + \cdots + a_{nn}\vec{e}_n.
\]

Мы будем считать две системы векторов \emph{эквивалентными}, если для построенных на них
$n$-мерных параллелепипедах выполняются условия:

\begin{enumerate}
    \item Они имеют одинаковый $n$-мерный объём.
    \item Порядок векторов у них совпадает.
\end{enumerate}

Класс эквивалентности таких систем мы называем \emph{$n$-вектором} и обозначаем так
\[
\vec{a}_1 \wedge \vec{a}_2 \wedge \cdots \wedge \vec{a}_n.
\]

\textbf{Пример 4.12.}
Вычислим внешнее произведение $n$ векторов:
\[
\vec{a}_1 \wedge \vec{a}_2 \wedge \cdots \wedge \vec{a}_n
=
(a_{11}\vec{e}_1 + \cdots + a_{1n}\vec{e}_n)\wedge
(a_{21}\vec{e}_1 + \cdots + a_{2n}\vec{e}_n)\wedge
\cdots\wedge
(a_{n1}\vec{e}_1 + \cdots + a_{nn}\vec{e}_n).
\]

При раскрытии получим $n^n$ слагаемых вида:
\[
a_{1 i_1} a_{2 i_2}\cdots a_{n i_n} \,
 (\vec{e}_{i_1}\wedge \vec{e}_{i_2}\wedge \cdots \wedge \vec{e}_{i_n}),
\qquad
i_1,i_2,\dots,i_n\in\{1,2,\dots,n\}.
\]

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!60!black,title=Важное замечание]
Если среди индексов $i_1,i_2,\dots,i_n$ есть повторения, то
\[
\vec{e}_{i_1}\wedge\vec{e}_{i_2}\wedge \cdots \wedge \vec{e}_{i_n}=0.
\]
Поэтому остаются только слагаемые, где $i_1,i_2,\dots,i_n$ — различные индексы,
то есть перестановки множества $\{1,2,\dots,n\}$.

Всего таких перестановок $n!$.
\end{tcolorbox}

Для каждой перестановки $\sigma\in S_n$ получаем слагаемое:
\[
a_{1\sigma(1)}a_{2\sigma(2)}\cdots a_{n\sigma(n)}
\,
(\vec{e}_{\sigma(1)}\wedge\vec{e}_{\sigma(2)}\wedge \cdots \wedge \vec{e}_{\sigma(n)}).
\]

Упростим выражения с базисными векторами.  
Для любой перестановки $\sigma$:
\[
\vec{e}_{\sigma(1)}\wedge\vec{e}_{\sigma(2)}\wedge\cdots\wedge\vec{e}_{\sigma(n)}
=
\operatorname{sign}(\sigma)\cdot(\vec{e}_1\wedge\vec{e}_2\wedge\cdots\wedge\vec{e}_n),
\]
где $\operatorname{sign}(\sigma)$ — знак перестановки $\sigma$.

Подставим обратно:
\[
\vec{a}_1\wedge\vec{a}_2\wedge\cdots\wedge\vec{a}_n
=
\left(
\sum_{\sigma\in S_n}
\operatorname{sign}(\sigma)\,
a_{1\sigma(1)}a_{2\sigma(2)}\cdots a_{n\sigma(n)}
\right)
\cdot
(\vec{e}_1\wedge\vec{e}_2\wedge\cdots\wedge\vec{e}_n).
\]

Сумма в скобках — это в точности определение детерминанта матрицы:
\[
A=
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{pmatrix}.
\]

\begin{tcolorbox}[colback=red!5!white,colframe=red!60!black,title=Важное замечание]
Таким образом, мы получаем фундаментальную формулу:
\[
\vec{a}_1\wedge\vec{a}_2\wedge\cdots\wedge\vec{a}_n
=
\det(A)\cdot (\vec{e}_1 \wedge \vec{e}_2 \wedge \cdots \wedge \vec{e}_n),
\]
где коэффициент пропорциональности бивектора $\vec{a}_1\wedge\cdots\wedge\vec{a}_n$
к базисному бивектору $\vec{e}_1\wedge\vec{e}_2\wedge\cdots\wedge\vec{e}_n$
называется \emph{детерминантом матрицы} $A$:
\[
\det(A)
=
\sum_{\sigma\in S_n}
\operatorname{sign}(\sigma)\,
a_{1\sigma(1)}a_{2\sigma(2)}\cdots a_{n\sigma(n)}.
\]
\end{tcolorbox}



	\textit{Источник: \emph{Linear-Algebra}, глава 4, \S4.2.1--4.2.5 ``Понятие бивектора, тривектора и $n$-векторов'', стр.\ 76--82.}
\end{answerbox}

\bigskip

% ==========================
% ЧАСТЬ II. ТЕОРЕМЫ
% ==========================

\section*{Часть II. Теоремы}
\addcontentsline{toc}{section}{Часть II. Теоремы}

% 1. Эквивалентные расширенные матрицы

\theoremq{Если расширенные матрицы двух линейных систем эквивалентны, то эти системы имеют одно и то же множество решений. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Пусть две линейные системы имеют расширенные матрицы $M$ и $M'$, причём $M'$ получается из $M$ конечной последовательностью элементарных преобразований строк. Тогда множества решений этих систем совпадают.

	\medskip

	\textbf{Идея доказательства.}
	Достаточно показать, что каждое отдельное элементарное преобразование строк не меняет множества решений системы. Умножение строки на ненулевое число, прибавление к строке другой строки, умноженной на число, и перестановка строк не изменяют множества векторов $x$, удовлетворяющих всем уравнениям: новые уравнения являются линейными комбинациями старых и наоборот. Композиция таких шагов также сохраняет множество решений.

	\medskip

	\textbf{Доказательство.}
	Обозначим уравнения исходной системы через $L_i(x)=b_i$. Рассмотрим, например, первое преобразование: замену $i$-го уравнения на $L_i(x)+\lambda L_j(x)=b_i+\lambda b_j$. Если $x$ удовлетворяет исходной системе, то $L_i(x)=b_i$ и $L_j(x)=b_j$, а значит $L_i(x)+\lambda L_j(x)=b_i+\lambda b_j$, то есть $x$ удовлетворяет и новой системе. Обратное верно, так как из новой системы можно обратно получить старую, прибавив к модифицированному уравнению $(-\lambda)$-кратное $j$-е. Аналогично разбираются умножение строки на ненулевой скаляр и перестановка строк (перестановка просто меняет порядок уравнений). Поскольку эквивалентность по строкам получается композицией таких шагов, множества решений исходной и преобразованной систем совпадают.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, теорема 1.1.1 и её разбор, стр.\ 11--13.}
\end{answerbox}

\bigskip

% 2. Приведение к ступенчатому виду

\theoremq{Любую матрицу с помощью элементарных преобразований можно привести к ступенчатому виду, а также к редуцированному ступенчатому виду. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Для любой матрицы $A\in\operatorname{Mat}_{m\times n}(\mathbb{R})$ существует конечная последовательность элементарных преобразований строк, после которой матрица приобретает ступенчатый вид, а затем~--- и приведённый ступенчатый вид.

	\medskip

	\textbf{Идея доказательства.}
	Используется пошаговый алгоритм: ищется самый левый ненулевой столбец, внутри него выбирается ненулевая строка как опорная, ниже неё зануляются элементы этим ведущим элементом; затем те же действия повторяются для подматрицы, лежащей правее и ниже. Это даёт ступенчатый вид. После этого нормируем ведущие элементы до $1$ и зануляем элементы над ними, получая приведённый вид.

	\medskip

	\textbf{Доказательство.}
	Если $A$~--- нулевая матрица, она уже имеет ступенчатый вид. Иначе пусть $j$~--- номер самого левого ненулевого столбца. Переставляя строки (элементарными операциями), можно добиться, чтобы элемент $a_{1j}\neq 0$ (если он не в первой строке). Используя операции вида
	\[
		r_i \leftarrow r_i - \frac{a_{ij}}{a_{1j}} r_1,\quad i>1,
	\]
	зануляем все элементы ниже $a_{1j}$ в этом столбце. Получаем матрицу вида
	\[
		\begin{pmatrix}
			0      & \dots & 0      & a_{1j} & *      & \dots & *      \\
			0      & \dots & 0      & 0      & *      & \dots & *      \\
			\vdots &       & \vdots & \vdots & \vdots &       & \vdots
		\end{pmatrix}.
	\]
	Рассмотрим подматрицу, образованную строками со 2-й по $m$ и столбцами с $(j+1)$-го по $n$; применяем к ней тот же алгоритм. Индукцией по числу строк (или по размеру подматрицы) получаем ступенчатый вид. Чтобы получить приведённый ступенчатый вид, делим каждую ненулевую строку на её ведущий элемент (деление на ненулевое число~--- элементарное преобразование) и затем вычитаем подходящие кратные этой строки из строк выше, чтобы занулить элементы над ведущими. В результате ведущие элементы становятся равны $1$ и единственными ненулевыми в своих столбцах.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#1, теорема 1.1.2 и её доказательство, стр.\ 14--15.}
\end{answerbox}

\bigskip

% 3. Решения однородной системы — подпространство

\theoremq{Множество всех решений какой-то однородной линейной системы от $n$ переменных есть подпространство в $\mathbb{R}^n$. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Пусть задана однородная система $m$ линейных уравнений с $n$ неизвестными
	\[
		\begin{cases}
			a_{11}x_1 + \dots + a_{1n}x_n = 0, \\
			\vdots                             \\
			a_{m1}x_1 + \dots + a_{mn}x_n = 0.
		\end{cases}
	\]
	Множество всех её решений $S\subset\mathbb{R}^n$ является векторным подпространством в $\mathbb{R}^n$.

	\medskip

	\textbf{Доказательство.}
	Проверим три условия подпространства.

	1) Нулевой вектор $0 = (0,\dots,0)^\top$ очевидно является решением, так как подстановка даёт $0=0$ в каждом уравнении, значит $0\in S$.

	2) Если $s=(s_1,\dots,s_n)$ и $t=(t_1,\dots,t_n)$~--- решения, то для каждого уравнения
	\[
		a_{i1}s_1 + \dots + a_{in}s_n = 0,\qquad
		a_{i1}t_1 + \dots + a_{in}t_n = 0.
	\]
	Складывая, получаем
	\[
		a_{i1}(s_1+t_1) + \dots + a_{in}(s_n+t_n) = 0,
	\]
	значит $s+t$ тоже решение и $s+t\in S$.

	3) Если $s=(s_1,\dots,s_n)$~--- решение и $\lambda\in\mathbb{R}$, то
	\[
		a_{i1}(\lambda s_1) + \dots + a_{in}(\lambda s_n) = \lambda(a_{i1}s_1 + \dots + a_{in}s_n) = \lambda\cdot 0 = 0,
	\]
	то есть $\lambda s$ также решение, $\lambda s\in S$.

	Следовательно, $S$ замкнуто относительно сложения и умножения на скаляр и содержит нулевой вектор, значит является подпространством.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#2, предложение 2.1.2, стр.\ 24--25.}
\end{answerbox}

\bigskip

% 4. Линейная оболочка — векторное пространство

\theoremq{Линейная оболочка является векторным пространством. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Пусть $S\subset V$~--- непустое множество векторов в векторном пространстве $V$. Тогда линейная оболочка $\operatorname{Lin}(S)$ является векторным подпространством $V$, а значит векторным пространством.

	\medskip

	\textbf{Доказательство.}
	По определению $\operatorname{Lin}(S)$ состоит из всех конечных линейных комбинаций элементов из $S$.

	1) Нулевой вектор $0$ принадлежит $\operatorname{Lin}(S)$, так как его можно записать как линейную комбинацию с нулевыми коэффициентами.

	2) Если $u = \sum_{i=1}^k \alpha_i s_i$ и $v = \sum_{j=1}^\ell \beta_j t_j$~--- два вектора из $\operatorname{Lin}(S)$ (где $s_i,t_j\in S$), то их сумма
	\[
		u+v = \sum_{i=1}^k \alpha_i s_i + \sum_{j=1}^\ell \beta_j t_j
	\]
	снова является конечной линейной комбинацией элементов из $S$, значит $u+v\in\operatorname{Lin}(S)$.

	3) Для любого $\lambda\in\mathbb{R}$ и $u = \sum_{i=1}^k \alpha_i s_i\in\operatorname{Lin}(S)$ имеем
	\[
		\lambda u = \sum_{i=1}^k (\lambda \alpha_i) s_i,
	\]
	что снова линейная комбинация элементов из $S$, поэтому $\lambda u\in\operatorname{Lin}(S)$.

	Итак, $\operatorname{Lin}(S)$ удовлетворяет условиям подпространства и является векторным пространством.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#3, обсуждение линейной оболочки как порождённого подпространства, стр.\ 26--27.}
\end{answerbox}

\bigskip

% 5. Стандартный базис в R^n

\theoremq{В пространстве $\mathbb{R}^n$ рассмотрим следующие $n$ векторов $e_1=(1,0,\dots,0),\dots,e_n=(0,\dots,0,1)$. Эти векторы образуют базис пространства $\mathbb{R}^n$, который принято называть стандартным базисом. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Векторы $e_1,\dots,e_n$, где $e_i$ имеет $1$ на $i$-й позиции и нули на остальных, образуют базис $\mathbb{R}^n$.

	\medskip

	\textbf{Доказательство.}
	1) Любой вектор $x=(x_1,\dots,x_n)^\top\in\mathbb{R}^n$ можно представить как
	\[
		x = x_1 e_1 + \dots + x_n e_n,
	\]
	то есть $e_1,\dots,e_n$ порождают всё пространство $\mathbb{R}^n$.

	2) Если
	\[
		\alpha_1 e_1 + \dots + \alpha_n e_n = 0,
	\]
	то левая часть есть $(\alpha_1,\dots,\alpha_n)^\top$, а значит $\alpha_i=0$ для всех $i$. Следовательно, векторы линейно независимы.

	Таким образом, $e_1,\dots,e_n$ линейно независимы и порождают $\mathbb{R}^n$, то есть составляют базис.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#2, пример со стандартным базисом в $\mathbb{R}^n$, стр.\ 18--20.}
\end{answerbox}

\bigskip

% 6. Любое конечномерное пространство изоморфно R^n

\theoremq{Если $V$~--- векторное пространство размерности $n$, то оно изоморфно пространству $\mathbb{R}^n$. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Пусть $V$~--- векторное пространство над $\mathbb{R}$ размерности $n$. Тогда существует линейный изоморфизм $\varphi\colon V\to\mathbb{R}^n$.

	\medskip

	\textbf{Доказательство.}
	Выберем базис $B=(v_1,\dots,v_n)$ пространства $V$. Любой вектор $v\in V$ единственным образом представим как $v=\alpha_1 v_1 + \dots + \alpha_n v_n$. Определим отображение
	\[
		\varphi\colon V\to\mathbb{R}^n,\qquad
		\varphi(v) =
		\begin{pmatrix}
			\alpha_1 \\ \vdots\\ \alpha_n
		\end{pmatrix}.
	\]
	Тогда $\varphi$ линейно, так как коэффициенты линейной комбинации зависят линейно от самого вектора: $\varphi(v+w)=\varphi(v)+\varphi(w)$, $\varphi(\lambda v)=\lambda\varphi(v)$. Инъективность: если $\varphi(v)=0$, то все координаты $\alpha_i=0$, значит $v=0$. Сюръективность: для любого $x=(x_1,\dots,x_n)^\top\in\mathbb{R}^n$ вектор $v = x_1 v_1 + \dots + x_n v_n$ удовлетворяет $\varphi(v)=x$. Следовательно, $\varphi$~--- биективное линейное отображение, то есть изоморфизм.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#5, \S2.4.3 ``Все конечномерные пространства это $\mathbb{R}^n$'', стр.\ 39--40.}
\end{answerbox}

\bigskip

% 7. Достаточно знать образы базисных векторов

\theoremq{Любое линейное отображение $f\colon\mathbb{R}^n\to\mathbb{R}^m$ достаточно задать на базисных векторах, то есть если знать чему равны $f(e_1),\dots,f(e_n)$, то этого достаточно чтобы узнать чему равно $f(v)$ для любого $v\in\mathbb{R}^n$. Докажите и объясните.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Пусть $f\colon\mathbb{R}^n\to\mathbb{R}^m$~--- линейное отображение, а $e_1,\dots,e_n$~--- стандартный базис в $\mathbb{R}^n$. Тогда для любого $v\in\mathbb{R}^n$ вектор $f(v)$ однозначно выражается через $f(e_1),\dots,f(e_n)$, причём
	\[
		v = x_1 e_1 + \dots + x_n e_n
		\quad\Rightarrow\quad
		f(v) = x_1 f(e_1) + \dots + x_n f(e_n).
	\]

	\medskip

	\textbf{Доказательство.}
	Любой $v\in\mathbb{R}^n$ можно единственно записать в виде $v = x_1 e_1 + \dots + x_n e_n$. Линейность даёт
	\[
		f(v) = f(x_1 e_1 + \dots + x_n e_n)
		= x_1 f(e_1) + \dots + x_n f(e_n).
	\]
	Тем самым, зная значения $f$ на базисных векторах, можно восстановить значение $f$ на любом векторе. Обратное тоже верно: любые выборы $m$-мерных векторов $f(e_1),\dots,f(e_n)$ единственным образом продолжаются до линейного отображения $f$ по приведённой формуле.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#6, \S3.1.2 ``Пример: почему достаточно знать образы базисных векторов'', стр.\ 41--43.}
\end{answerbox}

\bigskip

% 8. Композиция и матрицы

\theoremq{Пусть есть три конечномерных векторных пространства $\mathbb{R}^n, \mathbb{R}^k, \mathbb{R}^m$ и два линейных отображения $g\colon\mathbb{R}^n\to\mathbb{R}^k$, $f\colon\mathbb{R}^k\to\mathbb{R}^m$. Пусть $g$ записывается матрицей $A$, а $f$ матрицей $B$. Тогда $f\circ g$ записывается матрицей $B A$. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	В стандартных базисах для $\mathbb{R}^n,\mathbb{R}^k,\mathbb{R}^m$ матрица композиции $f\circ g$ равна произведению матриц $B A$.

	\medskip

	\textbf{Доказательство.}
	Пусть $x\in\mathbb{R}^n$~--- столбец координат. Тогда
	\[
		g(x) = A x \in\mathbb{R}^k,\qquad
		f(g(x)) = B (A x) = (B A) x.
	\]
	То есть действие композиции $f\circ g$ на произвольный вектор $x$ описывается умножением на матрицу $B A$. Поскольку любое линейное отображение на $\mathbb{R}^n$--$\mathbb{R}^m$ однозначно определяется своим действием на векторах, это и есть матрица композиции.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#7, \S3.2.2, стр.\ 51--52.}
\end{answerbox}

\bigskip

% 9. Решение Ax=b через A^{-1}

\theoremq{Если квадратная матрица $A\in\operatorname{Mat}_{n\times n}(\mathbb{R})$ обратима, тогда для каждого вектора $b\in\mathbb{R}^n$ уравнение $A x = b$ имеет единственное решение $x = A^{-1} b$. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Если $A$ обратима, то для любого $b\in\mathbb{R}^n$ линейное уравнение $A x = b$ имеет единственное решение $x=A^{-1} b$.

	\medskip

	\textbf{Доказательство.}
	Пусть $A^{-1}$~--- обратная матрица к $A$. Если $A x = b$, умножим это равенство слева на $A^{-1}$:
	\[
		A^{-1} A x = A^{-1} b \quad\Rightarrow\quad E x = A^{-1} b \quad\Rightarrow\quad x = A^{-1} b.
	\]
	Значит любой возможный корень обязан иметь вид $A^{-1} b$. С другой стороны, если положить $x_0 = A^{-1} b$, то
	\[
		A x_0 = A (A^{-1} b) = (A A^{-1}) b = E b = b,
	\]
	то есть $x_0$ действительно решение. Единственность вытекает из того, что если $A x_1 = b$ и $A x_2 = b$, то $A(x_1-x_2)=0$. Но $A$ обратима, значит $x_1-x_2=0$ и $x_1=x_2$.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#8, \S3.3.2 ``Нахождение обратной матрицы'' и \S3.1.4 ``Решение матричного уравнения $A x = b$'', стр.\ 49--50 и 58--59.}
\end{answerbox}

\bigskip

% 10. Критерий обратимости через эквивалентность единичной

\theoremq{Матрица $A\in\operatorname{Mat}_{n\times n}(\mathbb{R})$ обратима тогда и только тогда, когда она эквивалентна по строкам единичной матрице $E$. Докажите.}

\begin{answerbox}[title={Формулировка и доказательство}]
	\textbf{Формулировка.}
	Квадратная матрица $A$ обратима $\Leftrightarrow$ существует последовательность элементарных преобразований строк, переводящая $A$ в единичную матрицу $E_n$.

	\medskip

	\textbf{Доказательство.}

	\emph{($\Rightarrow$)} Пусть $A$ обратима. Решая систему $A X = E_n$ методом Гаусса, мы применяем элементарные преобразования строк к расширенной матрице $(A\mid E_n)$, стремясь получить $(E_n\mid A^{-1})$. Левая часть в процессе преобразований как раз принимает вид $E_n$, что означает эквивалентность по строкам $A\sim E_n$.

	\emph{($\Leftarrow$)} Пусть теперь $A$ эквивалентна $E_n$ по строкам. Последовательность элементарных преобразований строк реализуется умножением слева на произведение элементарных матриц $E_k\cdots E_1$, так что
	\[
		E_k \cdots E_1 A = E_n.
	\]
	Пусть $C = E_k\cdots E_1$. Тогда $C A = E_n$. Поскольку каждая элементарная матрица обратима, произведение $C$ тоже обратимо, и, следовательно, $A$ имеет левую обратную $C$. Аналогично можно рассмотреть преобразования, возвращающие $E_n$ в $A$, и получить правую обратную. В конечномерном случае левая и правая обратимые матрицы совпадают, значит $A$ обратима.

	\textit{Источник: \emph{Linear-Algebra}, лекция \#8, \S3.3.4 ``Критерий обратимости матрицы'', стр.\ 60--61.}
\end{answerbox}

\end{document}